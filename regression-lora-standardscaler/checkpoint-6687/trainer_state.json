{
  "best_global_step": 6687,
  "best_metric": 34.2546501159668,
  "best_model_checkpoint": "./regression-lora-standardscaler/checkpoint-6687",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 6687,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13458950201884254,
      "grad_norm": 44.60340118408203,
      "learning_rate": 9.866756393001347e-05,
      "loss": 1.0566,
      "step": 100
    },
    {
      "epoch": 0.2691790040376851,
      "grad_norm": 29.576622009277344,
      "learning_rate": 9.732166890982503e-05,
      "loss": 0.3202,
      "step": 200
    },
    {
      "epoch": 0.4037685060565276,
      "grad_norm": 24.45482063293457,
      "learning_rate": 9.597577388963661e-05,
      "loss": 0.2795,
      "step": 300
    },
    {
      "epoch": 0.5383580080753702,
      "grad_norm": 37.180450439453125,
      "learning_rate": 9.462987886944818e-05,
      "loss": 0.2783,
      "step": 400
    },
    {
      "epoch": 0.6729475100942126,
      "grad_norm": 13.674328804016113,
      "learning_rate": 9.328398384925976e-05,
      "loss": 0.2371,
      "step": 500
    },
    {
      "epoch": 0.8075370121130552,
      "grad_norm": 2.4632058143615723,
      "learning_rate": 9.193808882907134e-05,
      "loss": 0.2177,
      "step": 600
    },
    {
      "epoch": 0.9421265141318977,
      "grad_norm": 36.49525451660156,
      "learning_rate": 9.059219380888291e-05,
      "loss": 0.203,
      "step": 700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.2226281762123108,
      "eval_mae": 46.83462142944336,
      "eval_mse": 4340.859375,
      "eval_runtime": 45.2307,
      "eval_samples_per_second": 114.966,
      "eval_steps_per_second": 4.112,
      "step": 743
    },
    {
      "epoch": 1.0767160161507403,
      "grad_norm": 2.176194190979004,
      "learning_rate": 8.924629878869449e-05,
      "loss": 0.2968,
      "step": 800
    },
    {
      "epoch": 1.2113055181695827,
      "grad_norm": 70.9369888305664,
      "learning_rate": 8.790040376850605e-05,
      "loss": 0.3226,
      "step": 900
    },
    {
      "epoch": 1.3458950201884252,
      "grad_norm": 11.695072174072266,
      "learning_rate": 8.655450874831763e-05,
      "loss": 0.2488,
      "step": 1000
    },
    {
      "epoch": 1.4804845222072678,
      "grad_norm": 2.368356943130493,
      "learning_rate": 8.52086137281292e-05,
      "loss": 0.2082,
      "step": 1100
    },
    {
      "epoch": 1.6150740242261103,
      "grad_norm": 37.85850143432617,
      "learning_rate": 8.386271870794078e-05,
      "loss": 0.1757,
      "step": 1200
    },
    {
      "epoch": 1.749663526244953,
      "grad_norm": 7.79306697845459,
      "learning_rate": 8.251682368775236e-05,
      "loss": 0.2003,
      "step": 1300
    },
    {
      "epoch": 1.8842530282637955,
      "grad_norm": 12.756457328796387,
      "learning_rate": 8.117092866756393e-05,
      "loss": 0.1964,
      "step": 1400
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.17857246100902557,
      "eval_mae": 37.185115814208984,
      "eval_mse": 3482.21875,
      "eval_runtime": 44.9623,
      "eval_samples_per_second": 115.652,
      "eval_steps_per_second": 4.137,
      "step": 1486
    },
    {
      "epoch": 2.018842530282638,
      "grad_norm": 22.742977142333984,
      "learning_rate": 7.982503364737551e-05,
      "loss": 0.1604,
      "step": 1500
    },
    {
      "epoch": 2.1534320323014806,
      "grad_norm": 23.012874603271484,
      "learning_rate": 7.847913862718709e-05,
      "loss": 0.2391,
      "step": 1600
    },
    {
      "epoch": 2.288021534320323,
      "grad_norm": 33.023231506347656,
      "learning_rate": 7.713324360699866e-05,
      "loss": 0.2003,
      "step": 1700
    },
    {
      "epoch": 2.4226110363391653,
      "grad_norm": 7.441025733947754,
      "learning_rate": 7.578734858681024e-05,
      "loss": 0.1935,
      "step": 1800
    },
    {
      "epoch": 2.557200538358008,
      "grad_norm": 30.029203414916992,
      "learning_rate": 7.444145356662182e-05,
      "loss": 0.1721,
      "step": 1900
    },
    {
      "epoch": 2.6917900403768504,
      "grad_norm": 21.285964965820312,
      "learning_rate": 7.309555854643338e-05,
      "loss": 0.1954,
      "step": 2000
    },
    {
      "epoch": 2.826379542395693,
      "grad_norm": 1.8494478464126587,
      "learning_rate": 7.174966352624496e-05,
      "loss": 0.1676,
      "step": 2100
    },
    {
      "epoch": 2.9609690444145356,
      "grad_norm": 20.271286010742188,
      "learning_rate": 7.040376850605653e-05,
      "loss": 0.1878,
      "step": 2200
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.17262357473373413,
      "eval_mae": 40.690757751464844,
      "eval_mse": 3366.2841796875,
      "eval_runtime": 44.4221,
      "eval_samples_per_second": 117.059,
      "eval_steps_per_second": 4.187,
      "step": 2229
    },
    {
      "epoch": 3.095558546433378,
      "grad_norm": 15.327214241027832,
      "learning_rate": 6.905787348586811e-05,
      "loss": 0.162,
      "step": 2300
    },
    {
      "epoch": 3.2301480484522207,
      "grad_norm": 14.197598457336426,
      "learning_rate": 6.771197846567968e-05,
      "loss": 0.1762,
      "step": 2400
    },
    {
      "epoch": 3.3647375504710633,
      "grad_norm": 29.37013053894043,
      "learning_rate": 6.636608344549126e-05,
      "loss": 0.2205,
      "step": 2500
    },
    {
      "epoch": 3.499327052489906,
      "grad_norm": 17.824018478393555,
      "learning_rate": 6.502018842530282e-05,
      "loss": 0.1486,
      "step": 2600
    },
    {
      "epoch": 3.6339165545087484,
      "grad_norm": 22.568134307861328,
      "learning_rate": 6.36742934051144e-05,
      "loss": 0.145,
      "step": 2700
    },
    {
      "epoch": 3.768506056527591,
      "grad_norm": 11.088788986206055,
      "learning_rate": 6.232839838492598e-05,
      "loss": 0.2076,
      "step": 2800
    },
    {
      "epoch": 3.9030955585464335,
      "grad_norm": 6.482146263122559,
      "learning_rate": 6.098250336473755e-05,
      "loss": 0.1557,
      "step": 2900
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.15705059468746185,
      "eval_mae": 35.54368209838867,
      "eval_mse": 3061.626953125,
      "eval_runtime": 44.7088,
      "eval_samples_per_second": 116.308,
      "eval_steps_per_second": 4.16,
      "step": 2972
    },
    {
      "epoch": 4.037685060565276,
      "grad_norm": 12.388357162475586,
      "learning_rate": 5.963660834454913e-05,
      "loss": 0.2139,
      "step": 3000
    },
    {
      "epoch": 4.172274562584119,
      "grad_norm": 16.513385772705078,
      "learning_rate": 5.82907133243607e-05,
      "loss": 0.1914,
      "step": 3100
    },
    {
      "epoch": 4.306864064602961,
      "grad_norm": 33.97309875488281,
      "learning_rate": 5.6944818304172276e-05,
      "loss": 0.1551,
      "step": 3200
    },
    {
      "epoch": 4.441453566621804,
      "grad_norm": 19.547094345092773,
      "learning_rate": 5.559892328398385e-05,
      "loss": 0.1471,
      "step": 3300
    },
    {
      "epoch": 4.576043068640646,
      "grad_norm": 33.13451385498047,
      "learning_rate": 5.425302826379542e-05,
      "loss": 0.1911,
      "step": 3400
    },
    {
      "epoch": 4.710632570659489,
      "grad_norm": 10.186060905456543,
      "learning_rate": 5.2907133243607e-05,
      "loss": 0.1568,
      "step": 3500
    },
    {
      "epoch": 4.845222072678331,
      "grad_norm": 10.904752731323242,
      "learning_rate": 5.1561238223418575e-05,
      "loss": 0.1726,
      "step": 3600
    },
    {
      "epoch": 4.979811574697173,
      "grad_norm": 4.369137287139893,
      "learning_rate": 5.0215343203230144e-05,
      "loss": 0.1661,
      "step": 3700
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.16575171053409576,
      "eval_mae": 39.4466552734375,
      "eval_mse": 3232.554931640625,
      "eval_runtime": 45.1129,
      "eval_samples_per_second": 115.266,
      "eval_steps_per_second": 4.123,
      "step": 3715
    },
    {
      "epoch": 5.114401076716016,
      "grad_norm": 26.64992332458496,
      "learning_rate": 4.886944818304173e-05,
      "loss": 0.1932,
      "step": 3800
    },
    {
      "epoch": 5.248990578734858,
      "grad_norm": 4.129034519195557,
      "learning_rate": 4.7523553162853304e-05,
      "loss": 0.1219,
      "step": 3900
    },
    {
      "epoch": 5.383580080753701,
      "grad_norm": 14.411885261535645,
      "learning_rate": 4.6177658142664873e-05,
      "loss": 0.1962,
      "step": 4000
    },
    {
      "epoch": 5.518169582772543,
      "grad_norm": 9.883109092712402,
      "learning_rate": 4.483176312247645e-05,
      "loss": 0.1438,
      "step": 4100
    },
    {
      "epoch": 5.652759084791386,
      "grad_norm": 16.06440544128418,
      "learning_rate": 4.3485868102288026e-05,
      "loss": 0.1626,
      "step": 4200
    },
    {
      "epoch": 5.787348586810229,
      "grad_norm": 3.2613024711608887,
      "learning_rate": 4.2139973082099596e-05,
      "loss": 0.1415,
      "step": 4300
    },
    {
      "epoch": 5.921938088829071,
      "grad_norm": 6.23545503616333,
      "learning_rate": 4.079407806191117e-05,
      "loss": 0.1344,
      "step": 4400
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.1574699729681015,
      "eval_mae": 34.746299743652344,
      "eval_mse": 3072.6494140625,
      "eval_runtime": 44.2455,
      "eval_samples_per_second": 117.526,
      "eval_steps_per_second": 4.204,
      "step": 4458
    },
    {
      "epoch": 6.056527590847914,
      "grad_norm": 7.313697338104248,
      "learning_rate": 3.944818304172275e-05,
      "loss": 0.1718,
      "step": 4500
    },
    {
      "epoch": 6.191117092866756,
      "grad_norm": 10.600240707397461,
      "learning_rate": 3.810228802153432e-05,
      "loss": 0.133,
      "step": 4600
    },
    {
      "epoch": 6.325706594885599,
      "grad_norm": 10.525339126586914,
      "learning_rate": 3.6756393001345895e-05,
      "loss": 0.1717,
      "step": 4700
    },
    {
      "epoch": 6.460296096904441,
      "grad_norm": 4.266490936279297,
      "learning_rate": 3.541049798115747e-05,
      "loss": 0.1342,
      "step": 4800
    },
    {
      "epoch": 6.594885598923284,
      "grad_norm": 21.327880859375,
      "learning_rate": 3.406460296096904e-05,
      "loss": 0.2025,
      "step": 4900
    },
    {
      "epoch": 6.7294751009421265,
      "grad_norm": 2.0687499046325684,
      "learning_rate": 3.271870794078062e-05,
      "loss": 0.1203,
      "step": 5000
    },
    {
      "epoch": 6.864064602960969,
      "grad_norm": 21.403438568115234,
      "learning_rate": 3.1372812920592194e-05,
      "loss": 0.1429,
      "step": 5100
    },
    {
      "epoch": 6.998654104979812,
      "grad_norm": 22.627748489379883,
      "learning_rate": 3.0026917900403774e-05,
      "loss": 0.1436,
      "step": 5200
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.1562301367521286,
      "eval_mae": 34.302268981933594,
      "eval_mse": 3046.856201171875,
      "eval_runtime": 44.6586,
      "eval_samples_per_second": 116.439,
      "eval_steps_per_second": 4.165,
      "step": 5201
    },
    {
      "epoch": 7.133243606998654,
      "grad_norm": 1.9063390493392944,
      "learning_rate": 2.8681022880215347e-05,
      "loss": 0.1604,
      "step": 5300
    },
    {
      "epoch": 7.267833109017497,
      "grad_norm": 6.366754531860352,
      "learning_rate": 2.733512786002692e-05,
      "loss": 0.1288,
      "step": 5400
    },
    {
      "epoch": 7.402422611036339,
      "grad_norm": 2.097566604614258,
      "learning_rate": 2.5989232839838496e-05,
      "loss": 0.1595,
      "step": 5500
    },
    {
      "epoch": 7.537012113055182,
      "grad_norm": 3.046156644821167,
      "learning_rate": 2.464333781965007e-05,
      "loss": 0.1331,
      "step": 5600
    },
    {
      "epoch": 7.6716016150740245,
      "grad_norm": 5.972926139831543,
      "learning_rate": 2.3297442799461646e-05,
      "loss": 0.1291,
      "step": 5700
    },
    {
      "epoch": 7.806191117092867,
      "grad_norm": 10.894025802612305,
      "learning_rate": 2.195154777927322e-05,
      "loss": 0.1612,
      "step": 5800
    },
    {
      "epoch": 7.94078061911171,
      "grad_norm": 8.02899169921875,
      "learning_rate": 2.060565275908479e-05,
      "loss": 0.1207,
      "step": 5900
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.15696994960308075,
      "eval_mae": 34.339805603027344,
      "eval_mse": 3060.232421875,
      "eval_runtime": 44.9119,
      "eval_samples_per_second": 115.782,
      "eval_steps_per_second": 4.141,
      "step": 5944
    },
    {
      "epoch": 8.075370121130552,
      "grad_norm": 2.5587048530578613,
      "learning_rate": 1.9259757738896368e-05,
      "loss": 0.1131,
      "step": 6000
    },
    {
      "epoch": 8.209959623149395,
      "grad_norm": 11.454480171203613,
      "learning_rate": 1.791386271870794e-05,
      "loss": 0.1108,
      "step": 6100
    },
    {
      "epoch": 8.344549125168237,
      "grad_norm": 26.515321731567383,
      "learning_rate": 1.6567967698519514e-05,
      "loss": 0.1048,
      "step": 6200
    },
    {
      "epoch": 8.47913862718708,
      "grad_norm": 6.457111358642578,
      "learning_rate": 1.522207267833109e-05,
      "loss": 0.1481,
      "step": 6300
    },
    {
      "epoch": 8.613728129205922,
      "grad_norm": 12.960885047912598,
      "learning_rate": 1.3876177658142667e-05,
      "loss": 0.1434,
      "step": 6400
    },
    {
      "epoch": 8.748317631224765,
      "grad_norm": 21.868070602416992,
      "learning_rate": 1.2530282637954242e-05,
      "loss": 0.1451,
      "step": 6500
    },
    {
      "epoch": 8.882907133243608,
      "grad_norm": 3.214648485183716,
      "learning_rate": 1.1184387617765815e-05,
      "loss": 0.1566,
      "step": 6600
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.15648162364959717,
      "eval_mae": 34.2546501159668,
      "eval_mse": 3052.1591796875,
      "eval_runtime": 43.3497,
      "eval_samples_per_second": 119.955,
      "eval_steps_per_second": 4.291,
      "step": 6687
    }
  ],
  "logging_steps": 100,
  "max_steps": 7430,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.1941636832068895e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
