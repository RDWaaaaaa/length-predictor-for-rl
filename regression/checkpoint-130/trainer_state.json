{
  "best_global_step": 130,
  "best_metric": 50.346107482910156,
  "best_model_checkpoint": "./regression/checkpoint-130",
  "epoch": 0.17496635262449528,
  "eval_steps": 10,
  "global_step": 130,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0013458950201884253,
      "grad_norm": 141.1359100341797,
      "learning_rate": 0.0001,
      "loss": 4.0335,
      "step": 1
    },
    {
      "epoch": 0.0026917900403768506,
      "grad_norm": 203.38316345214844,
      "learning_rate": 9.998654104979812e-05,
      "loss": 6.7299,
      "step": 2
    },
    {
      "epoch": 0.004037685060565276,
      "grad_norm": 220.74620056152344,
      "learning_rate": 9.997308209959623e-05,
      "loss": 5.9174,
      "step": 3
    },
    {
      "epoch": 0.005383580080753701,
      "grad_norm": 175.8697509765625,
      "learning_rate": 9.995962314939436e-05,
      "loss": 4.0022,
      "step": 4
    },
    {
      "epoch": 0.006729475100942127,
      "grad_norm": 220.3738555908203,
      "learning_rate": 9.994616419919247e-05,
      "loss": 2.6758,
      "step": 5
    },
    {
      "epoch": 0.008075370121130552,
      "grad_norm": 228.40460205078125,
      "learning_rate": 9.993270524899059e-05,
      "loss": 3.2634,
      "step": 6
    },
    {
      "epoch": 0.009421265141318977,
      "grad_norm": 325.9924011230469,
      "learning_rate": 9.99192462987887e-05,
      "loss": 3.1585,
      "step": 7
    },
    {
      "epoch": 0.010767160161507403,
      "grad_norm": 212.7351531982422,
      "learning_rate": 9.990578734858681e-05,
      "loss": 2.7121,
      "step": 8
    },
    {
      "epoch": 0.012113055181695828,
      "grad_norm": 160.95045471191406,
      "learning_rate": 9.989232839838493e-05,
      "loss": 2.8304,
      "step": 9
    },
    {
      "epoch": 0.013458950201884253,
      "grad_norm": 86.65849304199219,
      "learning_rate": 9.987886944818304e-05,
      "loss": 1.4581,
      "step": 10
    },
    {
      "epoch": 0.013458950201884253,
      "eval_loss": 1.487882137298584,
      "eval_mae": 134.01820373535156,
      "eval_mse": 29015.48046875,
      "eval_runtime": 42.2391,
      "eval_samples_per_second": 123.109,
      "eval_steps_per_second": 4.403,
      "step": 10
    },
    {
      "epoch": 0.014804845222072678,
      "grad_norm": 24.103792190551758,
      "learning_rate": 9.986541049798115e-05,
      "loss": 1.5692,
      "step": 11
    },
    {
      "epoch": 0.016150740242261104,
      "grad_norm": 91.4270248413086,
      "learning_rate": 9.985195154777928e-05,
      "loss": 1.207,
      "step": 12
    },
    {
      "epoch": 0.017496635262449527,
      "grad_norm": 143.26345825195312,
      "learning_rate": 9.98384925975774e-05,
      "loss": 1.6032,
      "step": 13
    },
    {
      "epoch": 0.018842530282637954,
      "grad_norm": 83.61724853515625,
      "learning_rate": 9.982503364737551e-05,
      "loss": 1.0887,
      "step": 14
    },
    {
      "epoch": 0.020188425302826378,
      "grad_norm": 80.97644805908203,
      "learning_rate": 9.981157469717362e-05,
      "loss": 1.0463,
      "step": 15
    },
    {
      "epoch": 0.021534320323014805,
      "grad_norm": 68.9186782836914,
      "learning_rate": 9.979811574697175e-05,
      "loss": 0.7988,
      "step": 16
    },
    {
      "epoch": 0.02288021534320323,
      "grad_norm": 66.52259826660156,
      "learning_rate": 9.978465679676986e-05,
      "loss": 0.7984,
      "step": 17
    },
    {
      "epoch": 0.024226110363391656,
      "grad_norm": 21.218181610107422,
      "learning_rate": 9.977119784656798e-05,
      "loss": 1.2254,
      "step": 18
    },
    {
      "epoch": 0.02557200538358008,
      "grad_norm": 69.67930603027344,
      "learning_rate": 9.975773889636609e-05,
      "loss": 1.2437,
      "step": 19
    },
    {
      "epoch": 0.026917900403768506,
      "grad_norm": 60.502220153808594,
      "learning_rate": 9.97442799461642e-05,
      "loss": 1.0776,
      "step": 20
    },
    {
      "epoch": 0.026917900403768506,
      "eval_loss": 0.8238701820373535,
      "eval_mae": 99.45967102050781,
      "eval_mse": 16066.2109375,
      "eval_runtime": 42.3307,
      "eval_samples_per_second": 122.842,
      "eval_steps_per_second": 4.394,
      "step": 20
    },
    {
      "epoch": 0.02826379542395693,
      "grad_norm": 58.85602569580078,
      "learning_rate": 9.973082099596232e-05,
      "loss": 0.7762,
      "step": 21
    },
    {
      "epoch": 0.029609690444145357,
      "grad_norm": 49.730899810791016,
      "learning_rate": 9.971736204576043e-05,
      "loss": 0.6635,
      "step": 22
    },
    {
      "epoch": 0.03095558546433378,
      "grad_norm": 42.992530822753906,
      "learning_rate": 9.970390309555854e-05,
      "loss": 0.8145,
      "step": 23
    },
    {
      "epoch": 0.03230148048452221,
      "grad_norm": 19.51324462890625,
      "learning_rate": 9.969044414535667e-05,
      "loss": 0.5473,
      "step": 24
    },
    {
      "epoch": 0.033647375504710635,
      "grad_norm": 24.607330322265625,
      "learning_rate": 9.967698519515479e-05,
      "loss": 0.6576,
      "step": 25
    },
    {
      "epoch": 0.034993270524899055,
      "grad_norm": 44.372623443603516,
      "learning_rate": 9.96635262449529e-05,
      "loss": 0.737,
      "step": 26
    },
    {
      "epoch": 0.03633916554508748,
      "grad_norm": 31.3363094329834,
      "learning_rate": 9.965006729475101e-05,
      "loss": 0.5672,
      "step": 27
    },
    {
      "epoch": 0.03768506056527591,
      "grad_norm": 72.5978775024414,
      "learning_rate": 9.963660834454913e-05,
      "loss": 0.7706,
      "step": 28
    },
    {
      "epoch": 0.039030955585464336,
      "grad_norm": 43.91607666015625,
      "learning_rate": 9.962314939434725e-05,
      "loss": 0.5823,
      "step": 29
    },
    {
      "epoch": 0.040376850605652756,
      "grad_norm": 34.64518737792969,
      "learning_rate": 9.960969044414537e-05,
      "loss": 0.5656,
      "step": 30
    },
    {
      "epoch": 0.040376850605652756,
      "eval_loss": 0.6312944889068604,
      "eval_mae": 85.29790496826172,
      "eval_mse": 12309.798828125,
      "eval_runtime": 42.6256,
      "eval_samples_per_second": 121.993,
      "eval_steps_per_second": 4.364,
      "step": 30
    },
    {
      "epoch": 0.04172274562584118,
      "grad_norm": 27.22279167175293,
      "learning_rate": 9.959623149394348e-05,
      "loss": 0.4696,
      "step": 31
    },
    {
      "epoch": 0.04306864064602961,
      "grad_norm": 47.21781539916992,
      "learning_rate": 9.95827725437416e-05,
      "loss": 0.5698,
      "step": 32
    },
    {
      "epoch": 0.04441453566621804,
      "grad_norm": 45.366634368896484,
      "learning_rate": 9.956931359353971e-05,
      "loss": 0.4736,
      "step": 33
    },
    {
      "epoch": 0.04576043068640646,
      "grad_norm": 66.4975814819336,
      "learning_rate": 9.955585464333782e-05,
      "loss": 0.5695,
      "step": 34
    },
    {
      "epoch": 0.047106325706594884,
      "grad_norm": 54.679141998291016,
      "learning_rate": 9.954239569313593e-05,
      "loss": 0.4955,
      "step": 35
    },
    {
      "epoch": 0.04845222072678331,
      "grad_norm": 33.29780578613281,
      "learning_rate": 9.952893674293405e-05,
      "loss": 0.441,
      "step": 36
    },
    {
      "epoch": 0.04979811574697174,
      "grad_norm": 20.066410064697266,
      "learning_rate": 9.951547779273218e-05,
      "loss": 0.9208,
      "step": 37
    },
    {
      "epoch": 0.05114401076716016,
      "grad_norm": 51.88627243041992,
      "learning_rate": 9.950201884253029e-05,
      "loss": 0.4941,
      "step": 38
    },
    {
      "epoch": 0.052489905787348586,
      "grad_norm": 6.797237873077393,
      "learning_rate": 9.94885598923284e-05,
      "loss": 0.5123,
      "step": 39
    },
    {
      "epoch": 0.05383580080753701,
      "grad_norm": 56.20282745361328,
      "learning_rate": 9.947510094212652e-05,
      "loss": 0.4129,
      "step": 40
    },
    {
      "epoch": 0.05383580080753701,
      "eval_loss": 0.5163641571998596,
      "eval_mae": 76.811767578125,
      "eval_mse": 10069.2763671875,
      "eval_runtime": 42.7432,
      "eval_samples_per_second": 121.657,
      "eval_steps_per_second": 4.352,
      "step": 40
    },
    {
      "epoch": 0.05518169582772544,
      "grad_norm": 64.55591583251953,
      "learning_rate": 9.946164199192464e-05,
      "loss": 0.6749,
      "step": 41
    },
    {
      "epoch": 0.05652759084791386,
      "grad_norm": 11.767705917358398,
      "learning_rate": 9.944818304172276e-05,
      "loss": 0.5006,
      "step": 42
    },
    {
      "epoch": 0.05787348586810229,
      "grad_norm": 51.63793182373047,
      "learning_rate": 9.943472409152087e-05,
      "loss": 0.4237,
      "step": 43
    },
    {
      "epoch": 0.059219380888290714,
      "grad_norm": 41.845611572265625,
      "learning_rate": 9.942126514131898e-05,
      "loss": 0.5806,
      "step": 44
    },
    {
      "epoch": 0.06056527590847914,
      "grad_norm": 55.93998718261719,
      "learning_rate": 9.94078061911171e-05,
      "loss": 0.627,
      "step": 45
    },
    {
      "epoch": 0.06191117092866756,
      "grad_norm": 14.082387924194336,
      "learning_rate": 9.939434724091521e-05,
      "loss": 0.3295,
      "step": 46
    },
    {
      "epoch": 0.063257065948856,
      "grad_norm": 27.180139541625977,
      "learning_rate": 9.938088829071333e-05,
      "loss": 0.4437,
      "step": 47
    },
    {
      "epoch": 0.06460296096904442,
      "grad_norm": 18.065387725830078,
      "learning_rate": 9.936742934051144e-05,
      "loss": 0.5109,
      "step": 48
    },
    {
      "epoch": 0.06594885598923284,
      "grad_norm": 52.207035064697266,
      "learning_rate": 9.935397039030955e-05,
      "loss": 0.3382,
      "step": 49
    },
    {
      "epoch": 0.06729475100942127,
      "grad_norm": 52.48122024536133,
      "learning_rate": 9.934051144010768e-05,
      "loss": 0.4968,
      "step": 50
    },
    {
      "epoch": 0.06729475100942127,
      "eval_loss": 0.44722840189933777,
      "eval_mae": 71.59283447265625,
      "eval_mse": 8722.4580078125,
      "eval_runtime": 42.816,
      "eval_samples_per_second": 121.45,
      "eval_steps_per_second": 4.344,
      "step": 50
    },
    {
      "epoch": 0.06864064602960969,
      "grad_norm": 32.50882339477539,
      "learning_rate": 9.932705248990579e-05,
      "loss": 0.3258,
      "step": 51
    },
    {
      "epoch": 0.06998654104979811,
      "grad_norm": 22.832796096801758,
      "learning_rate": 9.93135935397039e-05,
      "loss": 0.383,
      "step": 52
    },
    {
      "epoch": 0.07133243606998654,
      "grad_norm": 11.71434497833252,
      "learning_rate": 9.930013458950202e-05,
      "loss": 0.3637,
      "step": 53
    },
    {
      "epoch": 0.07267833109017496,
      "grad_norm": 40.3509521484375,
      "learning_rate": 9.928667563930015e-05,
      "loss": 0.8517,
      "step": 54
    },
    {
      "epoch": 0.0740242261103634,
      "grad_norm": 22.887588500976562,
      "learning_rate": 9.927321668909826e-05,
      "loss": 0.3587,
      "step": 55
    },
    {
      "epoch": 0.07537012113055182,
      "grad_norm": 3.662381649017334,
      "learning_rate": 9.925975773889637e-05,
      "loss": 0.2966,
      "step": 56
    },
    {
      "epoch": 0.07671601615074024,
      "grad_norm": 17.17668342590332,
      "learning_rate": 9.924629878869449e-05,
      "loss": 0.2188,
      "step": 57
    },
    {
      "epoch": 0.07806191117092867,
      "grad_norm": 28.32199478149414,
      "learning_rate": 9.92328398384926e-05,
      "loss": 0.359,
      "step": 58
    },
    {
      "epoch": 0.07940780619111709,
      "grad_norm": 45.04258728027344,
      "learning_rate": 9.921938088829072e-05,
      "loss": 0.5498,
      "step": 59
    },
    {
      "epoch": 0.08075370121130551,
      "grad_norm": 39.1831169128418,
      "learning_rate": 9.920592193808883e-05,
      "loss": 0.2423,
      "step": 60
    },
    {
      "epoch": 0.08075370121130551,
      "eval_loss": 0.39399391412734985,
      "eval_mae": 63.562931060791016,
      "eval_mse": 7687.03515625,
      "eval_runtime": 42.8775,
      "eval_samples_per_second": 121.276,
      "eval_steps_per_second": 4.338,
      "step": 60
    },
    {
      "epoch": 0.08209959623149395,
      "grad_norm": 4.14608907699585,
      "learning_rate": 9.919246298788694e-05,
      "loss": 0.2988,
      "step": 61
    },
    {
      "epoch": 0.08344549125168237,
      "grad_norm": 55.653709411621094,
      "learning_rate": 9.917900403768507e-05,
      "loss": 0.4932,
      "step": 62
    },
    {
      "epoch": 0.0847913862718708,
      "grad_norm": 48.46052551269531,
      "learning_rate": 9.916554508748318e-05,
      "loss": 0.3768,
      "step": 63
    },
    {
      "epoch": 0.08613728129205922,
      "grad_norm": 12.515522003173828,
      "learning_rate": 9.91520861372813e-05,
      "loss": 0.4623,
      "step": 64
    },
    {
      "epoch": 0.08748317631224764,
      "grad_norm": 22.843265533447266,
      "learning_rate": 9.913862718707941e-05,
      "loss": 1.7578,
      "step": 65
    },
    {
      "epoch": 0.08882907133243607,
      "grad_norm": 38.83025360107422,
      "learning_rate": 9.912516823687752e-05,
      "loss": 0.3959,
      "step": 66
    },
    {
      "epoch": 0.0901749663526245,
      "grad_norm": 20.580230712890625,
      "learning_rate": 9.911170928667565e-05,
      "loss": 0.3835,
      "step": 67
    },
    {
      "epoch": 0.09152086137281291,
      "grad_norm": 57.197811126708984,
      "learning_rate": 9.909825033647376e-05,
      "loss": 0.2091,
      "step": 68
    },
    {
      "epoch": 0.09286675639300135,
      "grad_norm": 22.922622680664062,
      "learning_rate": 9.908479138627188e-05,
      "loss": 0.2797,
      "step": 69
    },
    {
      "epoch": 0.09421265141318977,
      "grad_norm": 23.966318130493164,
      "learning_rate": 9.907133243606999e-05,
      "loss": 0.764,
      "step": 70
    },
    {
      "epoch": 0.09421265141318977,
      "eval_loss": 0.3718244433403015,
      "eval_mae": 65.31603240966797,
      "eval_mse": 7251.1494140625,
      "eval_runtime": 42.9404,
      "eval_samples_per_second": 121.098,
      "eval_steps_per_second": 4.332,
      "step": 70
    },
    {
      "epoch": 0.0955585464333782,
      "grad_norm": 51.73870086669922,
      "learning_rate": 9.90578734858681e-05,
      "loss": 0.3637,
      "step": 71
    },
    {
      "epoch": 0.09690444145356662,
      "grad_norm": 89.37953186035156,
      "learning_rate": 9.904441453566622e-05,
      "loss": 0.4823,
      "step": 72
    },
    {
      "epoch": 0.09825033647375504,
      "grad_norm": 38.43797302246094,
      "learning_rate": 9.903095558546433e-05,
      "loss": 0.2314,
      "step": 73
    },
    {
      "epoch": 0.09959623149394348,
      "grad_norm": 29.174808502197266,
      "learning_rate": 9.901749663526245e-05,
      "loss": 0.2838,
      "step": 74
    },
    {
      "epoch": 0.1009421265141319,
      "grad_norm": 12.769671440124512,
      "learning_rate": 9.900403768506057e-05,
      "loss": 0.2585,
      "step": 75
    },
    {
      "epoch": 0.10228802153432032,
      "grad_norm": 38.917015075683594,
      "learning_rate": 9.899057873485869e-05,
      "loss": 0.6394,
      "step": 76
    },
    {
      "epoch": 0.10363391655450875,
      "grad_norm": 55.440799713134766,
      "learning_rate": 9.89771197846568e-05,
      "loss": 0.2792,
      "step": 77
    },
    {
      "epoch": 0.10497981157469717,
      "grad_norm": 6.117122173309326,
      "learning_rate": 9.896366083445491e-05,
      "loss": 0.1757,
      "step": 78
    },
    {
      "epoch": 0.1063257065948856,
      "grad_norm": 30.31136703491211,
      "learning_rate": 9.895020188425304e-05,
      "loss": 0.2753,
      "step": 79
    },
    {
      "epoch": 0.10767160161507403,
      "grad_norm": 9.639201164245605,
      "learning_rate": 9.893674293405116e-05,
      "loss": 0.1539,
      "step": 80
    },
    {
      "epoch": 0.10767160161507403,
      "eval_loss": 0.3455066382884979,
      "eval_mae": 58.273677825927734,
      "eval_mse": 6737.69140625,
      "eval_runtime": 42.9807,
      "eval_samples_per_second": 120.985,
      "eval_steps_per_second": 4.328,
      "step": 80
    },
    {
      "epoch": 0.10901749663526245,
      "grad_norm": 34.51221466064453,
      "learning_rate": 9.892328398384927e-05,
      "loss": 0.3831,
      "step": 81
    },
    {
      "epoch": 0.11036339165545088,
      "grad_norm": 92.44823455810547,
      "learning_rate": 9.890982503364738e-05,
      "loss": 0.4219,
      "step": 82
    },
    {
      "epoch": 0.1117092866756393,
      "grad_norm": 17.32689666748047,
      "learning_rate": 9.88963660834455e-05,
      "loss": 0.1717,
      "step": 83
    },
    {
      "epoch": 0.11305518169582772,
      "grad_norm": 8.951614379882812,
      "learning_rate": 9.888290713324361e-05,
      "loss": 0.233,
      "step": 84
    },
    {
      "epoch": 0.11440107671601615,
      "grad_norm": 11.036683082580566,
      "learning_rate": 9.886944818304172e-05,
      "loss": 0.2008,
      "step": 85
    },
    {
      "epoch": 0.11574697173620457,
      "grad_norm": 70.800048828125,
      "learning_rate": 9.885598923283984e-05,
      "loss": 0.375,
      "step": 86
    },
    {
      "epoch": 0.11709286675639301,
      "grad_norm": 105.63758850097656,
      "learning_rate": 9.884253028263796e-05,
      "loss": 0.3849,
      "step": 87
    },
    {
      "epoch": 0.11843876177658143,
      "grad_norm": 53.30049133300781,
      "learning_rate": 9.882907133243608e-05,
      "loss": 0.3484,
      "step": 88
    },
    {
      "epoch": 0.11978465679676985,
      "grad_norm": 45.602455139160156,
      "learning_rate": 9.881561238223419e-05,
      "loss": 0.2193,
      "step": 89
    },
    {
      "epoch": 0.12113055181695828,
      "grad_norm": 8.8970308303833,
      "learning_rate": 9.88021534320323e-05,
      "loss": 0.1786,
      "step": 90
    },
    {
      "epoch": 0.12113055181695828,
      "eval_loss": 0.31009456515312195,
      "eval_mae": 55.30080032348633,
      "eval_mse": 6048.20361328125,
      "eval_runtime": 42.9874,
      "eval_samples_per_second": 120.966,
      "eval_steps_per_second": 4.327,
      "step": 90
    },
    {
      "epoch": 0.1224764468371467,
      "grad_norm": 82.46368408203125,
      "learning_rate": 9.878869448183042e-05,
      "loss": 2.8484,
      "step": 91
    },
    {
      "epoch": 0.12382234185733512,
      "grad_norm": 16.062095642089844,
      "learning_rate": 9.877523553162855e-05,
      "loss": 0.3213,
      "step": 92
    },
    {
      "epoch": 0.12516823687752354,
      "grad_norm": 33.39961242675781,
      "learning_rate": 9.876177658142666e-05,
      "loss": 0.5142,
      "step": 93
    },
    {
      "epoch": 0.126514131897712,
      "grad_norm": 32.823883056640625,
      "learning_rate": 9.874831763122477e-05,
      "loss": 0.3083,
      "step": 94
    },
    {
      "epoch": 0.1278600269179004,
      "grad_norm": 63.87201690673828,
      "learning_rate": 9.873485868102289e-05,
      "loss": 0.3394,
      "step": 95
    },
    {
      "epoch": 0.12920592193808883,
      "grad_norm": 33.1485710144043,
      "learning_rate": 9.8721399730821e-05,
      "loss": 0.1948,
      "step": 96
    },
    {
      "epoch": 0.13055181695827725,
      "grad_norm": 5.320491790771484,
      "learning_rate": 9.870794078061911e-05,
      "loss": 0.2436,
      "step": 97
    },
    {
      "epoch": 0.13189771197846567,
      "grad_norm": 24.416255950927734,
      "learning_rate": 9.869448183041723e-05,
      "loss": 0.279,
      "step": 98
    },
    {
      "epoch": 0.13324360699865412,
      "grad_norm": 65.93819427490234,
      "learning_rate": 9.868102288021534e-05,
      "loss": 0.3672,
      "step": 99
    },
    {
      "epoch": 0.13458950201884254,
      "grad_norm": 35.42648696899414,
      "learning_rate": 9.866756393001347e-05,
      "loss": 0.2122,
      "step": 100
    },
    {
      "epoch": 0.13458950201884254,
      "eval_loss": 0.2849322557449341,
      "eval_mae": 52.399356842041016,
      "eval_mse": 5557.3251953125,
      "eval_runtime": 43.0269,
      "eval_samples_per_second": 120.855,
      "eval_steps_per_second": 4.323,
      "step": 100
    },
    {
      "epoch": 0.13593539703903096,
      "grad_norm": 17.111543655395508,
      "learning_rate": 9.865410497981158e-05,
      "loss": 0.2858,
      "step": 101
    },
    {
      "epoch": 0.13728129205921938,
      "grad_norm": 11.258792877197266,
      "learning_rate": 9.86406460296097e-05,
      "loss": 0.4644,
      "step": 102
    },
    {
      "epoch": 0.1386271870794078,
      "grad_norm": 3.696735143661499,
      "learning_rate": 9.862718707940781e-05,
      "loss": 0.2224,
      "step": 103
    },
    {
      "epoch": 0.13997308209959622,
      "grad_norm": 32.44339370727539,
      "learning_rate": 9.861372812920594e-05,
      "loss": 0.273,
      "step": 104
    },
    {
      "epoch": 0.14131897711978467,
      "grad_norm": 22.144775390625,
      "learning_rate": 9.860026917900405e-05,
      "loss": 0.3206,
      "step": 105
    },
    {
      "epoch": 0.1426648721399731,
      "grad_norm": 33.07948303222656,
      "learning_rate": 9.858681022880216e-05,
      "loss": 0.2107,
      "step": 106
    },
    {
      "epoch": 0.1440107671601615,
      "grad_norm": 4.261508464813232,
      "learning_rate": 9.857335127860028e-05,
      "loss": 0.1547,
      "step": 107
    },
    {
      "epoch": 0.14535666218034993,
      "grad_norm": 42.4964599609375,
      "learning_rate": 9.855989232839839e-05,
      "loss": 0.3123,
      "step": 108
    },
    {
      "epoch": 0.14670255720053835,
      "grad_norm": 27.068389892578125,
      "learning_rate": 9.85464333781965e-05,
      "loss": 0.2607,
      "step": 109
    },
    {
      "epoch": 0.1480484522207268,
      "grad_norm": 7.536353588104248,
      "learning_rate": 9.853297442799462e-05,
      "loss": 0.1523,
      "step": 110
    },
    {
      "epoch": 0.1480484522207268,
      "eval_loss": 0.3081170320510864,
      "eval_mae": 55.323246002197266,
      "eval_mse": 6008.70751953125,
      "eval_runtime": 43.0927,
      "eval_samples_per_second": 120.67,
      "eval_steps_per_second": 4.316,
      "step": 110
    },
    {
      "epoch": 0.14939434724091522,
      "grad_norm": 41.771339416503906,
      "learning_rate": 9.851951547779273e-05,
      "loss": 0.3509,
      "step": 111
    },
    {
      "epoch": 0.15074024226110364,
      "grad_norm": 70.19424438476562,
      "learning_rate": 9.850605652759084e-05,
      "loss": 0.233,
      "step": 112
    },
    {
      "epoch": 0.15208613728129206,
      "grad_norm": 51.30635070800781,
      "learning_rate": 9.849259757738897e-05,
      "loss": 0.1685,
      "step": 113
    },
    {
      "epoch": 0.15343203230148048,
      "grad_norm": 5.464603424072266,
      "learning_rate": 9.847913862718709e-05,
      "loss": 0.2699,
      "step": 114
    },
    {
      "epoch": 0.15477792732166892,
      "grad_norm": 17.275217056274414,
      "learning_rate": 9.84656796769852e-05,
      "loss": 0.1565,
      "step": 115
    },
    {
      "epoch": 0.15612382234185734,
      "grad_norm": 5.211205959320068,
      "learning_rate": 9.845222072678331e-05,
      "loss": 0.3121,
      "step": 116
    },
    {
      "epoch": 0.15746971736204576,
      "grad_norm": 20.088579177856445,
      "learning_rate": 9.843876177658144e-05,
      "loss": 0.2809,
      "step": 117
    },
    {
      "epoch": 0.15881561238223418,
      "grad_norm": 40.5823974609375,
      "learning_rate": 9.842530282637955e-05,
      "loss": 0.2207,
      "step": 118
    },
    {
      "epoch": 0.1601615074024226,
      "grad_norm": 22.5347843170166,
      "learning_rate": 9.841184387617767e-05,
      "loss": 0.5202,
      "step": 119
    },
    {
      "epoch": 0.16150740242261102,
      "grad_norm": 36.132564544677734,
      "learning_rate": 9.839838492597578e-05,
      "loss": 0.2215,
      "step": 120
    },
    {
      "epoch": 0.16150740242261102,
      "eval_loss": 0.2808000147342682,
      "eval_mae": 52.398773193359375,
      "eval_mse": 5474.02783203125,
      "eval_runtime": 43.1919,
      "eval_samples_per_second": 120.393,
      "eval_steps_per_second": 4.306,
      "step": 120
    },
    {
      "epoch": 0.16285329744279947,
      "grad_norm": 5.569546699523926,
      "learning_rate": 9.83849259757739e-05,
      "loss": 0.2091,
      "step": 121
    },
    {
      "epoch": 0.1641991924629879,
      "grad_norm": 7.759527683258057,
      "learning_rate": 9.837146702557201e-05,
      "loss": 0.1776,
      "step": 122
    },
    {
      "epoch": 0.1655450874831763,
      "grad_norm": 45.504615783691406,
      "learning_rate": 9.835800807537012e-05,
      "loss": 0.3128,
      "step": 123
    },
    {
      "epoch": 0.16689098250336473,
      "grad_norm": 6.309889793395996,
      "learning_rate": 9.834454912516823e-05,
      "loss": 0.3272,
      "step": 124
    },
    {
      "epoch": 0.16823687752355315,
      "grad_norm": 24.080087661743164,
      "learning_rate": 9.833109017496636e-05,
      "loss": 0.4213,
      "step": 125
    },
    {
      "epoch": 0.1695827725437416,
      "grad_norm": 8.129334449768066,
      "learning_rate": 9.831763122476448e-05,
      "loss": 0.1496,
      "step": 126
    },
    {
      "epoch": 0.17092866756393002,
      "grad_norm": 53.362308502197266,
      "learning_rate": 9.830417227456259e-05,
      "loss": 0.2912,
      "step": 127
    },
    {
      "epoch": 0.17227456258411844,
      "grad_norm": 39.55575942993164,
      "learning_rate": 9.82907133243607e-05,
      "loss": 0.3557,
      "step": 128
    },
    {
      "epoch": 0.17362045760430686,
      "grad_norm": 95.14250946044922,
      "learning_rate": 9.827725437415882e-05,
      "loss": 0.3093,
      "step": 129
    },
    {
      "epoch": 0.17496635262449528,
      "grad_norm": 72.21224975585938,
      "learning_rate": 9.826379542395694e-05,
      "loss": 0.323,
      "step": 130
    },
    {
      "epoch": 0.17496635262449528,
      "eval_loss": 0.26070740818977356,
      "eval_mae": 50.346107482910156,
      "eval_mse": 5083.24560546875,
      "eval_runtime": 43.202,
      "eval_samples_per_second": 120.365,
      "eval_steps_per_second": 4.305,
      "step": 130
    }
  ],
  "logging_steps": 1,
  "max_steps": 7430,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 10,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.209679755575296e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
