{
  "best_global_step": 2229,
  "best_metric": 36.32341766357422,
  "best_model_checkpoint": "./regression/checkpoint-2229",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2229,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13458950201884254,
      "grad_norm": 16.220382690429688,
      "learning_rate": 9.866756393001347e-05,
      "loss": 1.9424,
      "step": 100
    },
    {
      "epoch": 0.2691790040376851,
      "grad_norm": 54.66599655151367,
      "learning_rate": 9.732166890982503e-05,
      "loss": 0.3128,
      "step": 200
    },
    {
      "epoch": 0.4037685060565276,
      "grad_norm": 6.883097171783447,
      "learning_rate": 9.597577388963661e-05,
      "loss": 0.2814,
      "step": 300
    },
    {
      "epoch": 0.5383580080753702,
      "grad_norm": 46.944122314453125,
      "learning_rate": 9.462987886944818e-05,
      "loss": 0.2952,
      "step": 400
    },
    {
      "epoch": 0.6729475100942126,
      "grad_norm": 48.54823684692383,
      "learning_rate": 9.328398384925976e-05,
      "loss": 0.2664,
      "step": 500
    },
    {
      "epoch": 0.8075370121130552,
      "grad_norm": 12.801915168762207,
      "learning_rate": 9.193808882907134e-05,
      "loss": 0.2361,
      "step": 600
    },
    {
      "epoch": 0.9421265141318977,
      "grad_norm": 1.7803010940551758,
      "learning_rate": 9.059219380888291e-05,
      "loss": 0.196,
      "step": 700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.21081359684467316,
      "eval_mae": 44.76351547241211,
      "eval_mse": 4109.931640625,
      "eval_runtime": 45.6554,
      "eval_samples_per_second": 113.897,
      "eval_steps_per_second": 4.074,
      "step": 743
    },
    {
      "epoch": 1.0767160161507403,
      "grad_norm": 19.54317855834961,
      "learning_rate": 8.924629878869449e-05,
      "loss": 0.3018,
      "step": 800
    },
    {
      "epoch": 1.2113055181695827,
      "grad_norm": 44.98804473876953,
      "learning_rate": 8.790040376850605e-05,
      "loss": 0.3166,
      "step": 900
    },
    {
      "epoch": 1.3458950201884252,
      "grad_norm": 5.498051643371582,
      "learning_rate": 8.655450874831763e-05,
      "loss": 0.2065,
      "step": 1000
    },
    {
      "epoch": 1.4804845222072678,
      "grad_norm": 19.486270904541016,
      "learning_rate": 8.52086137281292e-05,
      "loss": 0.2033,
      "step": 1100
    },
    {
      "epoch": 1.6150740242261103,
      "grad_norm": 19.998899459838867,
      "learning_rate": 8.386271870794078e-05,
      "loss": 0.172,
      "step": 1200
    },
    {
      "epoch": 1.749663526244953,
      "grad_norm": 27.25543975830078,
      "learning_rate": 8.251682368775236e-05,
      "loss": 0.2028,
      "step": 1300
    },
    {
      "epoch": 1.8842530282637955,
      "grad_norm": 46.78106689453125,
      "learning_rate": 8.117092866756393e-05,
      "loss": 0.1933,
      "step": 1400
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.17091399431228638,
      "eval_mae": 36.96654510498047,
      "eval_mse": 3332.733154296875,
      "eval_runtime": 45.2264,
      "eval_samples_per_second": 114.977,
      "eval_steps_per_second": 4.113,
      "step": 1486
    },
    {
      "epoch": 2.018842530282638,
      "grad_norm": 3.9275407791137695,
      "learning_rate": 7.982503364737551e-05,
      "loss": 0.1642,
      "step": 1500
    },
    {
      "epoch": 2.1534320323014806,
      "grad_norm": 11.468178749084473,
      "learning_rate": 7.847913862718709e-05,
      "loss": 0.241,
      "step": 1600
    },
    {
      "epoch": 2.288021534320323,
      "grad_norm": 22.628536224365234,
      "learning_rate": 7.713324360699866e-05,
      "loss": 0.1888,
      "step": 1700
    },
    {
      "epoch": 2.4226110363391653,
      "grad_norm": 14.592218399047852,
      "learning_rate": 7.578734858681024e-05,
      "loss": 0.1965,
      "step": 1800
    },
    {
      "epoch": 2.557200538358008,
      "grad_norm": 15.588621139526367,
      "learning_rate": 7.444145356662182e-05,
      "loss": 0.1608,
      "step": 1900
    },
    {
      "epoch": 2.6917900403768504,
      "grad_norm": 2.617223024368286,
      "learning_rate": 7.309555854643338e-05,
      "loss": 0.1938,
      "step": 2000
    },
    {
      "epoch": 2.826379542395693,
      "grad_norm": 6.236189365386963,
      "learning_rate": 7.174966352624496e-05,
      "loss": 0.1678,
      "step": 2100
    },
    {
      "epoch": 2.9609690444145356,
      "grad_norm": 23.097309112548828,
      "learning_rate": 7.040376850605653e-05,
      "loss": 0.1903,
      "step": 2200
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.1621924340724945,
      "eval_mae": 36.32341766357422,
      "eval_mse": 3163.004638671875,
      "eval_runtime": 45.3945,
      "eval_samples_per_second": 114.551,
      "eval_steps_per_second": 4.097,
      "step": 2229
    }
  ],
  "logging_steps": 100,
  "max_steps": 7430,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.01
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0647212282053919e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
